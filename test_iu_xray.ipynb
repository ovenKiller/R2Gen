{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from modules.tokenizers import Tokenizer\n",
    "from modules.dataloaders import R2DataLoader\n",
    "from modules.metrics import compute_scores\n",
    "from modules.tester import Tester\n",
    "from modules.loss import compute_loss\n",
    "from models.r2gen import R2GenModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# 模拟命令行参数\n",
    "sys.argv = [\n",
    "    'main_test.py',  # 脚本名\n",
    "    '--image_dir', 'data/iu_xray/images/',\n",
    "    '--ann_path', 'data/iu_xray/annotation.json',\n",
    "    '--dataset_name', 'iu_xray',\n",
    "    '--max_seq_length', '60',\n",
    "    '--threshold', '3',\n",
    "    '--batch_size', '16',\n",
    "    '--epochs', '100',\n",
    "    '--save_dir', 'results/iu_xray',\n",
    "    '--step_size', '50',\n",
    "    '--gamma', '0.1',\n",
    "    '--seed', '9223',\n",
    "    '--load', 'data/model_iu_xray.pth'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_agrs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data input settings\n",
    "    parser.add_argument('--image_dir', type=str, default='data/iu_xray/images/', help='the path to the directory containing the data.')\n",
    "    parser.add_argument('--ann_path', type=str, default='data/iu_xray/annotation.json', help='the path to the directory containing the data.')\n",
    "\n",
    "    # Data loader settings\n",
    "    parser.add_argument('--dataset_name', type=str, default='iu_xray', choices=['iu_xray', 'mimic_cxr'], help='the dataset to be used.')\n",
    "    parser.add_argument('--max_seq_length', type=int, default=60, help='the maximum sequence length of the reports.')\n",
    "    parser.add_argument('--threshold', type=int, default=3, help='the cut off frequency for the words.')\n",
    "    parser.add_argument('--num_workers', type=int, default=2, help='the number of workers for dataloader.')\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='the number of samples for a batch')\n",
    "\n",
    "    # Model settings (for visual extractor)\n",
    "    parser.add_argument('--visual_extractor', type=str, default='resnet101', help='the visual extractor to be used.')\n",
    "    parser.add_argument('--visual_extractor_pretrained', type=bool, default=True, help='whether to load the pretrained visual extractor')\n",
    "\n",
    "    # Model settings (for Transformer)\n",
    "    parser.add_argument('--d_model', type=int, default=512, help='the dimension of Transformer.')\n",
    "    parser.add_argument('--d_ff', type=int, default=512, help='the dimension of FFN.')\n",
    "    parser.add_argument('--d_vf', type=int, default=2048, help='the dimension of the patch features.')\n",
    "    parser.add_argument('--num_heads', type=int, default=8, help='the number of heads in Transformer.')\n",
    "    parser.add_argument('--num_layers', type=int, default=3, help='the number of layers of Transformer.')\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help='the dropout rate of Transformer.')\n",
    "    parser.add_argument('--logit_layers', type=int, default=1, help='the number of the logit layer.')\n",
    "    parser.add_argument('--bos_idx', type=int, default=0, help='the index of <bos>.')\n",
    "    parser.add_argument('--eos_idx', type=int, default=0, help='the index of <eos>.')\n",
    "    parser.add_argument('--pad_idx', type=int, default=0, help='the index of <pad>.')\n",
    "    parser.add_argument('--use_bn', type=int, default=0, help='whether to use batch normalization.')\n",
    "    parser.add_argument('--drop_prob_lm', type=float, default=0.5, help='the dropout rate of the output layer.')\n",
    "    # for Relational Memory\n",
    "    parser.add_argument('--rm_num_slots', type=int, default=3, help='the number of memory slots.')\n",
    "    parser.add_argument('--rm_num_heads', type=int, default=8, help='the numebr of heads in rm.')\n",
    "    parser.add_argument('--rm_d_model', type=int, default=512, help='the dimension of rm.')\n",
    "\n",
    "    # Sample related\n",
    "    parser.add_argument('--sample_method', type=str, default='beam_search', help='the sample methods to sample a report.')\n",
    "    parser.add_argument('--beam_size', type=int, default=3, help='the beam size when beam searching.')\n",
    "    parser.add_argument('--temperature', type=float, default=1.0, help='the temperature when sampling.')\n",
    "    parser.add_argument('--sample_n', type=int, default=1, help='the sample number per image.')\n",
    "    parser.add_argument('--group_size', type=int, default=1, help='the group size.')\n",
    "    parser.add_argument('--output_logsoftmax', type=int, default=1, help='whether to output the probabilities.')\n",
    "    parser.add_argument('--decoding_constraint', type=int, default=0, help='whether decoding constraint.')\n",
    "    parser.add_argument('--block_trigrams', type=int, default=1, help='whether to use block trigrams.')\n",
    "\n",
    "    # Trainer settings\n",
    "    parser.add_argument('--n_gpu', type=int, default=1, help='the number of gpus to be used.')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='the number of training epochs.')\n",
    "    parser.add_argument('--save_dir', type=str, default='results/iu_xray', help='the patch to save the models.')\n",
    "    parser.add_argument('--record_dir', type=str, default='records/', help='the patch to save the results of experiments')\n",
    "    parser.add_argument('--save_period', type=int, default=1, help='the saving period.')\n",
    "    parser.add_argument('--monitor_mode', type=str, default='max', choices=['min', 'max'], help='whether to max or min the metric.')\n",
    "    parser.add_argument('--monitor_metric', type=str, default='BLEU_4', help='the metric to be monitored.')\n",
    "    parser.add_argument('--early_stop', type=int, default=50, help='the patience of training.')\n",
    "\n",
    "    # Optimization\n",
    "    parser.add_argument('--optim', type=str, default='Adam', help='the type of the optimizer.')\n",
    "    parser.add_argument('--lr_ve', type=float, default=5e-5, help='the learning rate for the visual extractor.')\n",
    "    parser.add_argument('--lr_ed', type=float, default=1e-4, help='the learning rate for the remaining parameters.')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-5, help='the weight decay.')\n",
    "    parser.add_argument('--amsgrad', type=bool, default=True, help='.')\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    parser.add_argument('--lr_scheduler', type=str, default='StepLR', help='the type of the learning rate scheduler.')\n",
    "    parser.add_argument('--step_size', type=int, default=50, help='the step size of the learning rate scheduler.')\n",
    "    parser.add_argument('--gamma', type=float, default=0.1, help='the gamma of the learning rate scheduler.')\n",
    "\n",
    "    # Others\n",
    "    parser.add_argument('--seed', type=int, default=9233, help='.')\n",
    "    parser.add_argument('--resume', type=str, help='whether to resume the training from existing checkpoints.')\n",
    "    parser.add_argument('--load', type=str, help='whether to load a pre-trained model.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# parse arguments\n",
    "args = parse_agrs()\n",
    "\n",
    "# fix random seeds\n",
    "torch.manual_seed(args.seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "# create tokenizer\n",
    "tokenizer = Tokenizer(args)\n",
    "\n",
    "# create data loader\n",
    "test_dataloader = R2DataLoader(args, tokenizer, split='test', shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsq/.conda/envs/R2Gen/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/lsq/.conda/envs/R2Gen/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# build model architecture\n",
    "model = R2GenModel(args, tokenizer)\n",
    "\n",
    "# get function handles of loss and metrics\n",
    "criterion = compute_loss\n",
    "metrics = compute_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/04/2024 14:43:25 - INFO - modules.tester -   Loading checkpoint: data/model_iu_xray.pth ...\n"
     ]
    }
   ],
   "source": [
    "# build trainer and start to train\n",
    "tester = Tester(model, criterion, metrics, args, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/04/2024 14:43:28 - INFO - modules.tester -   Start to evaluate in the test set.\n",
      "37it [02:37,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_BLEU_1': 0.48806860551824394, 'test_BLEU_2': 0.31953319306629924, 'test_BLEU_3': 0.23254593954662917, 'test_BLEU_4': 0.17726137465520783, 'test_METEOR': 0.20223581292438503, 'test_ROUGE_L': 0.37190180397719386}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_BLEU_1': 0.48806860551824394,\n",
       " 'test_BLEU_2': 0.31953319306629924,\n",
       " 'test_BLEU_3': 0.23254593954662917,\n",
       " 'test_BLEU_4': 0.17726137465520783,\n",
       " 'test_METEOR': 0.20223581292438503,\n",
       " 'test_ROUGE_L': 0.37190180397719386}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R2Gen",
   "language": "python",
   "name": "r2gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
